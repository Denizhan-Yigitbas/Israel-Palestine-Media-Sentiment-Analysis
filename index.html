<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  <title>Israel/Palestine Sentiment Analysis</title>
  <link rel="stylesheet" href="fontawesome-5.5/css/all.min.css" />
  <link rel="stylesheet" href="slick/slick.css">
  <link rel="stylesheet" href="slick/slick-theme.css">
  <!-- <link rel="stylesheet" href="magnific-popup/magnific-popup.css"> -->
  <link rel="stylesheet" href="css/bootstrap.min.css" />
  <link rel="stylesheet" href="css/templatemo-style.css" />
</head>

<body>
  <!-- Hero section -->
  <section id="hero" class="text-white tm-font-big ">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-md tm-navbar" id="tmNav" style="z-index: 100;">
      <div class="container">
        <div class="tm-next">
          <a href="#hero" class="navbar-brand">Denizhan - SOCI 381</a>
        </div>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
          aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <i class="fas fa-bars navbar-toggler-icon"></i>
        </button>

        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link tm-nav-link" href="#background">Background</a>
            </li>
            <li class="nav-item">
              <a class="nav-link tm-nav-link" href="#hypothesis">Hypothesis</a>
            </li>
            <li class="nav-item">
              <a class="nav-link tm-nav-link" href="#methods">Methods</a>
            </li>
            <li class="nav-item">
              <a class="nav-link tm-nav-link" href="#results">Results</a>
            </li>
            <li class="nav-item">
              <a class="nav-link tm-nav-link" href="#future">Future Studies</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!--Lauch page text-->
    <div class="text-center tm-hero-text-container">
      <div class="tm-hero-text-container-inner">
        <h2 class="tm-hero-title">Exploring Sentiment Analysis of News Headlines</h2>
        <p class="tm-hero-subtitle">
          Moving the US Embassy from Tel Aviv to Jerusalem
          <br />
        <div class="tm-hero-author">By Denizhan Yigitbas </div>
        </p>
      </div>
    </div>

    <!-- Downarrow that leads to next section -->
    <div class="tm-next tm-intro-next">
      <a href="#background" class="text-center tm-down-arrow-link">
        <i class="fas fa-3x fa-caret-down tm-down-arrow"></i>
      </a>
    </div>
  </section>

  <section id="background" class="tm-section-pad-top">
    <div class="container tm-container-gallery">
      <div class="row">
        <div class="text-center">
          <h2 class="tm-text-primary tm-section-title mb-4">Background</h2>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            In recent years, data analytics has become an increasingly useful tool for researchers from all different
            disciplines. In the world of politics, a branch of data analytics called sentiment analysis has proven
            particularly useful for evaluating the overall emotion of any piece of text. Natural language processing
            (NLP) can classify any product review, news headline, even a tweet as a positive, negative, or neutral
            statement. In recent years, many companies have employed sentiment analysis on Twitter data sets in order to
            get a pulse on public opinion. For example, Apple might be interested in evaluating how customers feel about
            the new iPhone. To do so, they could extract tweets posted that contain the hashtag #iPhone and run a
            sentiment analysis on the data set to determine whether the majority of the content about the product is
            positive, negative, or neutral. Similarly, political campaigns could run a sentiment analysis on tweets
            posted by presidential candidates to determine how each politician's communications style affects polling
            numbers. Though the possibilities are endless, this study seeks to explore whether the same methodology
            could be applied to news headlines about the Israeli-Palestinian conflict. Given the complexity of this
            issue, my research project will focus on local news headlines covering Trump’s recent move of the US Embassy
            from Tel Aviv to Jerusalem.
          <h5 style="text-decoration: underline;">The Question</h5>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            <b>How is the US Embassy move depicted in American mainstream media? Is it
              possible to attribute a positive, negative, or neutral sentiment to news headlines connected to this
              event? Does the sentiment shift depending on the slant of the news source? </b> In order to explore these
            questions, four different news platforms will be analyzed: The New York Times, Fox News, Mondoweiss, and
            HonestReporting.
          </p>
          </p>
          <br>
          <img src="./img/all.jpg" width="90%" style="margin-bottom: 25px;">
        </div>
      </div>
    </div>
  </section>

  <hr style="width:30%; border: 1px solid #3496d8; border-radius: 5px; margin-top: 20px;">

  <section id="hypothesis" class="tm-section-pad-top">
    <div class="container tm-container-gallery">
      <div class="row">
        <div class="text-center">
          <h2 class="tm-text-primary tm-section-title mb-4">Hypothesis</h2>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            In order to proceed with the analysis, we must first define what is meant by a positive, negative, and
            neutral sentiment in the context of the US Embassy move from Tel Aviv to Jerusalem. This study assumes that
            a positive sentiment in a news headline about this event implies support of the move. Generally speaking,
            this position has typically been associated with those who support Israel. On the other hand, a negative
            sentiment within a headline conveys a lack of support for the move. Most often, this stance has typically
            been taken by those who support Palestine. With these assumptions in mind, I hypothesize that right-leaning
            platforms such as Fox News and HonestReporting will cover the move of the embassy with more positive
            sentiment, while left-leaning platforms such as The New York Times and Mondoweiss will cover the move with
            more negative sentiment.
          </p>
        </div>
      </div>
    </div>
  </section>

  <hr style="width:30%; border: 1px solid #3496d8; border-radius: 5px; margin-top: 20px;">

  <section id="methods" class="tm-section-pad-top">
    <div class="container tm-container-gallery">
      <div class="row">
        <div class="text-center">
          <h2 class="tm-text-primary tm-section-title mb-4">Methods</h2>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            Sentiment analysis can be performed in various ways, the most simple of which is called lexicon-based
            matching. There are three main parts to any lexicon-based matching process: data extraction, data cleaning,
            and data processing, which will be explained in more detail below. In order to complete all three steps,
            Python was used as the main backend software. Additionally, various application programming interfaces
            (APIs) and libraries were used to run my analyses. Once the necessary data processing was completed, excel
            and R were utilized to visualize the results.
          </p>
          <h5 style="text-decoration: underline;">Data Extraction</h5>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            The first step of any data science research project is collecting the data that will be analyzed. In the
            context of this project, I collected news headlines about the US Embassy move from Tel Aviv to Jerusalem
            from The New York Times, Fox News, Mondoweiss, and HonestReporting. Large platforms such as The New York
            Times and Fox News provide public APIs that allow developers to extract any desired data from these sources
            with simple software. For this reason, I was able to use a Python wrapper to extract approximately 50
            headlines from each news platform that were most relevant to the query "US Embassy move from Tel Aviv to
            Jerusalem." Smaller platforms such as Mondoweiss and HonestReporting do not provide such APIs, so the data
            from these sources were manually extracted using the same query. The data output for this step had the
            following structure:
          </p>
          <table>
            <tr>
              <th>Headline</th>
              <th>Source</th>
              <th>Search Query</th>
            </tr>
            <tr>
              <td>
                <div style="font-style: italic;">[News Headline]</div>
              </td>
              <td>
                <div style="font-style: italic;">[NYT, Fox, Mond, or HR]</div>
              </td>
              <td>
                <div style="font-style: italic;">US Embassy move from Tel Aviv to
                  Jerusalem</div>
              </td>
            </tr>
          </table>
          <br><br>
          <h5 style="text-decoration: underline;">Data Cleaning</h5>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            After compiling the desired headlines following data extraction, these headlines must be prepared for a
            lexicon-based matching analysis by removing or modifying any irrelevant, duplicated, or incorrect data.
            Oftentimes this step can become very involved when performing a sentiment analysis on something like product
            reviews posted on Twitter--if the pieces of text being used contain links, hashtags, mentions, or symbols,
            this information needs to be removed since they do not provide the analyzer with any additional information.
            Nonetheless, this is not as much of an issue due to the nature of this study’s data set. Since the content
            being analysed is professionally written, the news headlines only contain letters, numbers, and punctuation.
            For this reason, the only significant data cleaning that needs to be performed is the removal of what are
            called stop words. Stop words include determiners, conjunctions, and prepositions such as “a,” “for,” “but,”
            “in,” etc. After the data cleaning has been completed, every character in the headline will be coded UTF-8
            to ensure consistency across the data set and avoid any additional errors later.

          <table class="arrowtable">
            <tr class="arrowtable">
              <th class="arrowtable">Original Headline</th>
              <th class="arrowtable"></th>
              <th class="arrowtable">Cleaned Headline</th>
            </tr>
            <tr class="arrowtable">
              <td class="arrowtable">
                <div style="font-style: italic;">Killings in Gaza, New Embassy in Jerusalem, and Peace as Distant as
                  Ever</div>
              </td>
              <td class="arrowtable">
                <img src="./img/arrow.png" width="70%">
              </td>
              <td class="arrowtable">
                <div style="font-style: italic;">Killings Gaza, New Embassy Jerusalem, Peace Distant Ever</div>
              </td>
            </tr>
          </table>
          <br><br>
          <h5 style="text-decoration: underline;">Data Processing</h5>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            Now that the necessary data has been extracted and cleaned, it is ready to undergo the sentiment analysis
            data processing. The basics of sentiment analysis can be outlined as a five step process:
            <br><br>
            <b><u>Step 1:</u> </b>Tokenize the input into component sentences based on punctuation. This can be
            completed with a simple string manipulation algorithm that detects spaces and punctuation and divides them
            accordingly.
            <br>
            <b><u>Step 2:</u> </b> Tag each token with a part-of-speech using a natural language processing algorithm.
            This can
            be completed utilizing the NLP algorithms provided by the used library.
            <br>
            <b><u>Step 3:</u> </b>Assign quantitative values to each token by matching them to a word lexicon. Each
            token will be matched with the corresponding word in a word lexicon. Once each token is matched to a
            quantitative value, a statistical average will be taken for the overall input.
            <br>
            <b><u>Step 4:</u> </b>Output a normalized polarity for the input between -1 and 1. In order to compare
            results, the averages will be normalized to values between -1 and 1.
            <br>
            <b><u>Step 5:</u> </b>Map the polarity of each input to a sentiment. Any polarity value greater than 0
            equates to positive sentiment. Similarly, any polarity value less than 0 equates to a negative sentiment.
            Finally, if the polarity is equal to zero, this implies a neutral sentiment.
            <br><br>
            In order to ensure accuracy of the results, the following three natural language processing libraries for
            sentiment analysis were used: TextBlob, Vader, and SentimentR. Using three different libraries allows for
            the use of three different lexicons. In addition, each library utlizes their own statistical analyses to
            assign a polarity to the overall sentence. In order to draw an accurate conclusion, we would expect the
            results to
            show a similar pattern across the three libraries regardless. While TextBlob and Vader are NLP libraries
            written in
            Python, SentimentR is a library written solely for R software. Various data transformation methods were used
            in order to combine the resulting data processing for all three libraries. Once combined, the data is
            prepared to be analyzed for results. The data output file following this data processing had the following
            structure:
          <table>
            <tr>
              <th>Headline</th>
              <th>Source</th>
              <th>Polarity</th>
              <th>Sentiment</th>
            </tr>
            <tr>
              <td>
                <div style="font-style: italic;">[News Headline]</div>
              </td>
              <td>
                <div style="font-style: italic;">[NYT, Fox, Mond, or HR]</div>
              </td>
              <td>
                <div style="font-style: italic;">0.5</div>
              </td>
              <td>
                <div style="font-style: italic;">positive</div>
              </td>
            </tr>
          </table>
          </p>
        </div>
      </div>
    </div>
  </section>

  <hr style="width:30%; border: 1px solid #3496d8; border-radius: 5px; margin-top: 20px;">

  <section id="results" class="tm-section-pad-top">
    <div class="container tm-container-gallery">
      <div class="row">
        <div class="text-center">
          <h2 class="tm-text-primary tm-section-title mb-4">Results</h2>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            To analyze if there are observable differences in sentiment between headlines from The New York Times, Fox
            News, Mondoweiss, and HonestReporting on the US Embassy move from Tel Aviv to Jerusalem, bar graph
            visualizations were used to compare results across news platforms. In each graph, the x-axis contains the
            three different natural language processing libraries that were used for sentiment analysis: TextBlob,
            Vader, and SentimentR. Each of these three libraries contains three bars representing positive, negative, or
            neutral sentiment. The y-axis of these graphs represents the number of articles. The results of this data
            visualization are displayed below:
          </p>
        </div>
      </div>

      <div class="row" style="padding-top: 20px;">
        <!-- NYT -->
        <div class="col-lg-6">
          <img src="./img/nyt_title.png" style="width: 100%;">
          <img src="./img/nyt_graph2.png" style="width: 90%;">
        </div>

        <!--FOX-->
        <div class="col-lg-6 ">
          <img src="./img/fox_title.png" style="width: 100%;">
          <img src="./img/fox_graph2.png" style="width: 90%;">
        </div>
      </div>

      <div class="row" style="padding-top: 20px;">
        <!--MOND-->
        <div class="col-lg-6">
          <img src="./img/mond_title.png" style="width: 100%;">
          <img src="./img/mond_graph2.png" style="width: 100%;">
        </div>

        <!--HONREP-->
        <div class="col-lg-6 ">
          <img src="./img/honrep_title.jpg" width="100%">
          <img src="./img/honrep_graph2.png" style="width: 100%;">
        </div>
      </div>

      <p class="mx-auto tm-work-description" style="text-align: justify;">
        Although these graphs reveal some insight, a very significant inconsistency is visible between the three
        sentiment analysis libraries across all four sources. Looking at The New York Times, while TextBlob and Vader
        analyses revealed a predominantly neutral sentiment, the SentimentR library primarily recorded positive and
        negative sentiment. Similarly for Fox News, TextBlob and Vader again counted more neutral headlines than
        positive or negative, however, running SentimentR on the same data set counted more negative headlines compared
        to neutral or positive. The variation between the three possible sentiments are even more amplified when we look
        at Mondoweiss and HonestReporting. For Mondoweiss, TextBlob recorded only 1 negative article, while SentimentR
        recorded 8. Along the same lines, TextBlob recorded only 2 negative headlines for HonestReporting, yet
        SentimentR recorded 7. In addition, Vader recorded 0 positive articles for HonestReporting while both TextBlob
        and Sentiment recorded at 2 each.
        <br><br>
        Because of these inconsistent results, manually observing the processed data would allow for better
        understanding of these bar graph visualizations. To do so, we stack the results of the processed data from all
        four sources into a single file. We will now compare the sentiment column between the three different libraries.
        By filtering out the headlines that had the same sentiment between all three libraries, we will be able to
        observe the headlines that are causing the differences across TextBlob, Vader, and SenimentR. Two notable
        headlines were as follows:
      </p>

      <table>
        <tr>
          <th>Headline</th>
          <th>Source</th>
          <th>TextBlob</th>
          <th>Vader</th>
          <th>SentimentR</th>
        </tr>
        <tr>
          <td>
            <div style="font-style: italic">
              Anyone who says Jerusalem embassy move was painless doesn't think Gazans are human beings
            </div>
          </td>
          <td>
            <div style="font-style: italic;">Mondoweiss</div>
          </td>
          <td>
            <div style="font-style: italic;">neutral</div>
          </td>
          <td>
            <div style="font-style: italic;">positive</div>
          </td>
          <td>
            <div style="font-style: italic;">negative</div>
          </td>
        </tr>
        <tr>
          <td>
            <div style="font-style: italic">
              Killings in Gaza, New Embassy in Jerusalem, and Peace as Distant as Ever
            </div>
          </td>
          <td>
            <div style="font-style: italic;">NYT</div>
          </td>
          <td>
            <div style="font-style: italic;">positive</div>
          </td>
          <td>
            <div style="font-style: italic;">negative</div>
          </td>
          <td>
            <div style="font-style: italic;">positive</div>
          </td>
        </tr>
      </table>

      <br>
      <p class="mx-auto tm-work-description" style="text-align: justify;">
        With these examples, it is obvious that the Mondoweiss article has a negative tone to it. Yet, the only
        sentiment analysis that marked it as negative was SentimentR. Furthermore, the other two libraries did not mark
        it consistently either--TextBlob marked the headline neutral, while Vader marked the headline positive. However,
        the second example listed illustrates the imperfections of the results from the SentimentR library. After
        reading “Killings in Gaza, New Embassy in Jerusalem, and Peace as Distant as Ever,” it becomes clear that the
        tone of this piece of text is obviously negative. Although Vader correctly marked the headline positive in this
        case, TextBlob and SentimentR both marked it negative.
        <br><br>
        As I continued to conduct further analysis, it became apparent that a lexicon-based matching method can return
        inconsistent results when individual words are assigned a value regardless of their context in the sentence. For
        instance, the Mondoweiss article uses the word “painless.” Out of context, the word “painless” can be thought of
        as something positive. However, in this specific headline, the word “painless” is being used hypothetically and
        carries a negative connotation. Similarly, the word “peace” is used in The New York Times article. While the
        word “peace” is typically thought of as a positive term, the phrase “peace as distant as ever” is quite
        negative. Therefore, we see that one of the limitations of this kind of study is that words used in headlines
        often have various contextual meanings that cannot be detected with this method of sentiment analysis.
        <br><br>
        Further observing the data visualizations revealed another limitation. The issue stems from an incorrect
        assumption made in the hypothesis stage of the study--at the start of this research project, I assumed that a
        positive sentiment in a news headline implies support of moving the US Embassy from Tel Aviv to Jerusalem and a
        negative sentiment in a headline conveys a lack of support for the move. However, examining this assumption more
        closely reveals that this positive and negative binary cannot confidently be drawn in lexicon-based matching.
        This is because a news article can easily lead with a headline that uses multiple negative words yet still
        supports the move of the embassy. Similarly, a news headline can also use very positive words yet still express
        support for the Palestinian side of the conflict. Given these possibilities, it becomes clear that positive,
        negative, and neutral sentiments cannot exclusively be attributed to either side of the political spectrum
        regarding the Israeli-Palestinian conflict.
        <br><br>
        Finally, more data inspection also revealed that media framing in the context of news headlines is usually
        subtle due to their limitation in length. It is obvious that a headline cannot exceed a certain word count in
        order to capture the reader's attention. Therefore, a particular platform’s bias is more often conveyed by the
        tone of the words rather than the words themselves. For example, an editor may choose to put words in quotations
        to add a hint of sarcasm that a lexicon-based matching algorithm would not detect. An example of this kind of
        camouflaged critique can be seen in an HonestReporting article titled, “Saeb Erekat ‘Threatens’ Violence Over US
        Embassy Move.” Without the quotations surrounding “threatens” this headline can be read as quite foreboding, yet
        the addition of the punctuation marks gives the statement a snarky edge. However, if we were to only match words
        in the headline to quantitative values, this tone would not be detected at all.
        <br><br>
        All in all, the results of this study have shown that a lexicon-based model is ultimately not a strong enough
        method to differentiate the sentiment of news headlines due to the analyzer’s inability to understand contextual
        meanings and categorical definitions. Nonetheless, both of these issues can be overcome using an alternative
        approach that employs supervised machine learning and neural networks.
      </p>

  </section>

  <hr style="width:30%; border: 1px solid #3496d8; border-radius: 5px; margin-top: 20px;">

  <section id="future" class="tm-section-pad-top">
    <div class="container tm-container-gallery">
      <div class="row">
        <div class="text-center">
          <h2 class="tm-text-primary tm-section-title mb-4">Future Studies</h2>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            Given the inconsistent findings of this study, we can see that applying lexicon-based matching to news
            headlines can often lead to inconclusive results depending on the NLP library that is being used. That being
            said, we do have a great opportunity to improve this study using a different approach called supervised
            learning.
            <br><br>
            First of all, one of the changes I would make is transitioning the focus of the study from headlines to full
            articles. We have noticed that headlines often do not have enough information to draw conclusions about the
            sentiment, however examining the contents of that same article can make the sentiment much more clear to us.
            Therefore, while the sentiment of the headline may simply seem neutral, in reality the article may have a
            significant political slant.
            <br><br>
            Supervised learning is an approach to creating artificial intelligence, where the program is given labeled
            input data and the expected output results. Given such a training set, the program will learn to classify
            unknown inputs into their respective categories. This method can best be understood using a simple
            visualization, shown below:
          </p>
          <img src="./img/supervised.png" style="margin-bottom: 20px;">
          <br>
          <p class="mx-auto tm-work-description" style="text-align: justify;">
            Imagine we have a set of 1000 images of fruits. The model can then manually be “trained” with 100 of these
            images, where each one is marked as either “an apple” or “not an apple.” Now with the remaining 900 images,
            we can simply use this model to predict if each one is either an apple or not an apple.
            <br><br>
            All that needs to be done is to replace the variables in this example. For this research project, our new
            input data will be a set of articles about a topic (for example, the US Embassy move). Our goal will be to
            classify each one as either supporting the move, against the move, or neutral. This gives us two categories
            that are very well defined, as opposed to the positive, negative, or neutral sentiments used in
            lexicon-based matching. We can extract 20% of the article dataset and manually tag them as “supporting,”
            “against,” or “neutral.”
            <br><br>
            This tagged set will become the training set, which can now be used to teach the machine learning model how
            to classify the other 900 images on its own. In order to improve the model’s accuracy, various machine
            learning algorithms can be tested such as support vector machines, Neural Networks, etc. Once the model is
            appropriately trained, it will be able to correctly classify the remaining 80% of the data as “supporting,”
            “against,” or “neutral” in regards to the US Embassy move from Tel Aviv to Jerusalem.
            <br><br>
            Thus, we see that although lexicon-based matching may not have been the ideal approach to analyzing
            sentiment within news headlines, this study has opened doors into new areas of research that can apply the
            complexities of machine learning and artificial intelligence to better understand the nuances of media bias
            in US mainstream media coverage of the Israeli-Palestinian conflict and beyond.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Contact -->
  <section id="contact" class="tm-section-pad-top" style="margin-top: 100px; margin-bottom: 0px;">
    <div class="container" style="background-color: #3496d8;">
      <div class="">
        <div>
          <p class="" style="color: #343e49; text-align: center; margin-bottom: 0px; padding-bottom: 70px;">
            <b>All source code can be found here: </b><a target="_blank"
              style="font-style: italic; color: black; text-decoration: underline;"
              href="https://github.com/Denizhan-Yigitbas/Israel-Palestine-Media-Sentiment-Analysis">Link</a>

            <br>

            <b>Inspired by: </b><a target="_blank" style="font-style: italic; color: black; text-decoration: underline;"
              href="https://amiham-singh.github.io/">https://amiham-singh.github.io/</a>
          </p>
        </div>
      </div>
    </div>
  </section>


  <script src="js/jquery-1.9.1.min.js"></script>
  <script src="slick/slick.min.js"></script>
  <script src="magnific-popup/jquery.magnific-popup.min.js"></script>
  <script src="js/jquery.singlePageNav.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script>

    function getOffSet() {
      var _offset = 450;
      var windowHeight = window.innerHeight;

      if (windowHeight > 500) {
        _offset = 400;
      }
      if (windowHeight > 680) {
        _offset = 300
      }
      if (windowHeight > 830) {
        _offset = 210;
      }

      return _offset;
    }

    function setParallaxPosition($doc, multiplier, $object) {
      var offset = getOffSet();
      var from_top = $doc.scrollTop(),
        bg_css = 'center ' + (multiplier * from_top - offset) + 'px';
      $object.css({ "background-position": bg_css });
    }

    // Parallax function
    // Adapted based on https://codepen.io/roborich/pen/wpAsm        
    var background_image_parallax = function ($object, multiplier, forceSet) {
      multiplier = typeof multiplier !== 'undefined' ? multiplier : 0.5;
      multiplier = 1 - multiplier;
      var $doc = $(document);
      // $object.css({ "background-attatchment": "fixed" });

      if (forceSet) {
        setParallaxPosition($doc, multiplier, $object);
      } else {
        $(window).scroll(function () {
          setParallaxPosition($doc, multiplier, $object);
        });
      }
    };

    var background_image_parallax_2 = function ($object, multiplier) {
      multiplier = typeof multiplier !== 'undefined' ? multiplier : 0.5;
      multiplier = 1 - multiplier;
      var $doc = $(document);
      $object.css({ "background-attachment": "fixed" });
      $(window).scroll(function () {
        var firstTop = $object.offset().top,
          pos = $(window).scrollTop(),
          yPos = Math.round((multiplier * (firstTop - pos)) - 186);

        var bg_css = 'center ' + yPos + 'px';

        $object.css({ "background-position": bg_css });
      });
    };

    $(function () {
      // Hero Section - Background Parallax
      background_image_parallax($(".tm-parallax"), 0.30, false);
      background_image_parallax_2($("#contact"), 0.80);

      // Handle window resize
      window.addEventListener('resize', function () {
        background_image_parallax($(".tm-parallax"), 0.30, true);
      }, true);

      // Detect window scroll and update navbar
      $(window).scroll(function (e) {
        if ($(document).scrollTop() > 120) {
          $('.tm-navbar').addClass("scroll");
        } else {
          $('.tm-navbar').removeClass("scroll");
        }
      });

      // Close mobile menu after click 
      $('#tmNav a').on('click', function () {
        $('.navbar-collapse').removeClass('show');
      })

      // Scroll to corresponding section with animation
      $('#tmNav').singlePageNav();

      // Add smooth scrolling to all links
      // https://www.w3schools.com/howto/howto_css_smooth_scroll.asp
      $("a").on('click', function (event) {
        if (this.hash !== "") {
          event.preventDefault();
          var hash = this.hash;

          $('html, body').animate({
            scrollTop: $(hash).offset().top
          }, 400, function () {
            window.location.hash = hash;
          });
        } // End if
      });

      // // Pop up
      // $('.tm-gallery').magnificPopup({
      //   delegate: 'a',
      //   type: 'image',
      //   gallery: { enabled: true }
      // });

    });
  </script>
</body>

</html>